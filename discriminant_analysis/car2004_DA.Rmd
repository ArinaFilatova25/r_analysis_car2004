---
output: html_document
error: FALSE
warning: FALSE
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(warning = FALSE, message = FALSE) 

library(scatterPlotMatrix)
library(candisc)
library(FSA)
library(ROCR) 
library(readxl)
library(ggplot2)
library(dplyr)
library(zoo)
library(caret)
library(car)
library(stats)
library(readr)
library(DT)
library(formattable)
library(hrbrthemes)
library(tidyverse)
library(plotly)
library(GGally)
library(psych)
library(qgraph)
library(corrplot)
library(factoextra)
library(MASS)
library(klaR)

print_df <- function(df) {
  datatable(df, 
            options = list(scrollX = TRUE,  # Горизонтальная прокрутка
                           pageLength = 10, 
                           autoWidth = TRUE),
            class = 'display nowrap',       # Отключение переноса текста для удобной прокрутки
            rownames = FALSE)               # Отключение номеров строк 
}

create_ggpairs <- function(data, density_diag = TRUE, fig_width = 15, fig_height = 7) {
  if (density_diag) {
    ggpairs(data, diag = list(continuous = "densityDiag", discrete = "barDiag", na = "naDiag", mapping = aes(fill = "red")), fig.width = fig_width, fig.height = fig_height)
  } else {
    ggpairs(data, diag = list(continuous = "barDiag", mapping = aes(fill = "red")), fig.width = fig_width, fig.height = fig_height)
  }
}

calculate_metrics <- function(confusion_matrix, class_column) {
  rownames(confusion_matrix) <- levels(class_column)
  colnames(confusion_matrix) <- levels(class_column)

  num_classes <- length(levels(class_column))
  metrics <- data.frame(
    Class = levels(class_column),
    Precision = numeric(num_classes),
    Recall = numeric(num_classes),
    F1_score = numeric(num_classes)
  )

  for (i in seq_len(num_classes)) {
    class_label <- levels(class_column)[i]

    TP <- confusion_matrix[class_label, class_label]
    FP <- sum(confusion_matrix[class_label, ]) - TP
    FN <- sum(confusion_matrix[, class_label]) - TP

    precision <- ifelse(TP + FP > 0, TP / (TP + FP), 0) 
    recall <- ifelse(TP + FN > 0, TP / (TP + FN), 0)    
    f1_score <- ifelse(precision + recall > 0, 2 * (precision * recall) / (precision + recall), 0) 

    metrics$Precision[i] <- round(precision, 2)
    metrics$Recall[i] <- round(recall, 2)
    metrics$F1_score[i] <- round(f1_score, 2)
  }

  metrics
}
```


# Классификация данных car2004

## Загрузка данных

```{r}
data_car <- read_excel("C:/Users/redmi/OneDrive/Документы/R analysis/car2004.xls", na = "*")
colnames(data_car) <- gsub("-", "_", colnames(data_car))

# Добавление доп.столбцов
data_car$Other <- ifelse(rowSums(data_car[c("Sport", "SportUtil", "Wagon", "Minivan", "Pickup")]) == 0, 1, 0)
data_car$Front_wheel <- ifelse(rowSums(data_car[c("All_wheel", "Rear_wheel")]) == 0, 1, 0)

# Создание категориальных переменных
data_car <- data_car %>%
mutate(
  Body_type = factor(case_when(
    Sport == 1 ~ 1,
    SportUtil == 1 ~ 2,
    Wagon == 1 ~ 3,
    Minivan == 1 ~ 4,
    Pickup == 1 ~ 5,
    Other == 1 ~ 6,
    TRUE ~ NA_integer_
  ), levels = c(1, 2, 3, 4, 5, 6), labels = c("Sport", "SportUtil", "Wagon", "Minivan", "Pickup", "Other"))
)

data_car <- data_car %>%
  mutate(
    Wheel_type = factor(case_when(
      All_wheel == 1 ~ 1,
      Rear_wheel == 1 ~ 2,
      Front_wheel == 1 ~ 3,
      TRUE ~ NA_integer_  
    ), levels = c(1, 2, 3), labels = c("All_wheel", "Rear_wheel", "Front_wheel"))
  )

head(data_car, 5) |>
 print_df()
```


1. ***Name*** - Название автомобиля - **качественный признак**
2. ***Sport*** - Спортивная машина (1=да, 0=нет) - **качественный признак**
Легкие,  обычно имеют мощные двигатели, способные развивать высокие скорости, чаще всего имеют задний или полный привод.
3. ***SportUtil*** - Внедорожник (тип кузова) (1=да, 0=нет) - **качественный признак**
Характеризуется высокой посадкой, вместительным салоном, большим клиренсом и возможностью полного привода. 
4. ***Wagon*** - Универсал (тип кузова) (1=да, 0=нет) - **качественный признак**
Характеризуется увеличенным багажным отсеком, обычно имеет передний или полный привод.
5. ***Minivan*** - Минивэн  (тип кузова) (1=да, 0=нет) - **качественный признак**
Характеризуется большим количеством места для пассажиров и багажа, наиболее характерен передний привод. Некоторые модели минивэнов предлагают неплохую экономию топлива, учитывая их размер и вместительность.
6. ***Pickup*** - Пикап  (тип кузова) (1=да, 0=нет) - **качественный признак**
Характеризуется мощными двигателями и возможностью заднего или полного приводов.  
7. ***All-wheel*** - Полный привод (1=да, 0=нет) - **качественный признак**
8. ***Rear-wheel*** - Задний привод (1=да, 0=нет) - **качественный признак**
9. ***Retail*** - Рекомендованная розничная цена в долларах (цена продажи диллером) - **количественный непрерывный**
10. ***Dealer*** - Закупочная цена для дилера в долларах - **количественный непрерывный**
11. ***Engine*** - Объем двигателя в литрах - **количественный дискретный**
12. ***Cylinders*** - Число цилиндров (=-1 для роторного двигателя) - **количественный дискретный**
13. ***Horsepower*** - Лошадиные силы - **количественный дискретный**
14. ***CityMPG*** - Ожидаемый пробег в милях на галлон топлива для автомобиля в условиях городского движения. - **количественный дискретный**
15. ***HW_MPG*** - Ожидаемый пробег в милях на галлон топлива для автомобиля в условиях движения по шоссе или трассе при постоянной скорости - **количественный дискретный**

В городском цикле обычно встречаются частые остановки, старты и пробки, что приводит к более частому использованию тормозов и ускорителей. Это может уменьшить экономию топлива.

В условиях шоссейного движения меньше остановок и меньше стартов, что может способствовать более высокой экономии топлива.

То есть ожидается, что HW_MPG > CityMPG.

16. ***Weight*** - Вес автомобиля в фунтах - **количественный непрерывный**
17. ***WheelBase*** -  Расстояние между передними и задними колесами в дюймах - **количественный дискретный**
18. ***Length*** - Длина автомобиля в дюймах - **количественный дискретный**
19. ***Width*** - Ширина автомобиля в дюймах - **количественный дискретный**

Были добавлены еще два столбца, которые соответствуют другому (то есть ни одному из представленных) типу кузова (***Other***) и переднему приводу (***Front_wheel***). 

Также были добавлены две категориальные переменные, отвечающие типу кузова (***Body_type***) и типу привода (***Wheel_type***).

Так как пропусков не так много, то заполним их медианным значением по каждому признаку.

```{r}
cols_to_fill <- c("CityMPG", "HW_MPG", "Weight", "WheelBase", "Length", "Width")
filled_cols <- na.aggregate(data_car[, cols_to_fill], FUN = median, na.rm = TRUE)
data_car[, cols_to_fill] <- filled_cols
```

Наблюдения Retail, Dealer, Engine, Horsepower, CityMPG, HW_MPG, Weight, WheelBase имеют хвост вправо, прологарифмируем их и построим графики зависимостей признаков. 

```{r chunk_name_1, fig.width=20, fig.height=13}
data_log <- data_car %>% 
  mutate_at(vars(Retail, Dealer, Engine, Horsepower, CityMPG, HW_MPG, Weight, WheelBase), ~log(.))

#Убираем сильно выделяющиеся наблюдения
data_log <- data_log[-c(69, 94, 70, 300, 97, 273, 272, 259, 305, 288, 241, 242, 419), ]

data_select <- data_log %>% dplyr::select(-Name, -Sport, -SportUtil,-Wagon, -Minivan, -Pickup, -All_wheel, -Rear_wheel, -Cylinders, -Other, -Front_wheel, -Body_type, -Wheel_type)

create_ggpairs(data_select, density_diag = FALSE) 
```

**Расстояние Махаланобиса между группами по типу кузова**

```{r}
predictors <- c("Retail", "Engine", "Horsepower", "CityMPG", "HW_MPG", "Weight", "WheelBase", "Length", "Width")
data_predictors <- data_log[,predictors]
```


```{r}
mahalanobis_distances <- function(data, group){
  groups <- split(data, group)

  covariances <- lapply(groups, cov)
  centers <- lapply(groups, colMeans)

  mahalanobis_distance <- function(group1, group2, cov1, cov2, center1, center2){
    common_covariance <- (cov1 + cov2)/2
    mahalanobis(center1, center2, common_covariance)
  }

  distances <- matrix(NA, length(groups), length(groups))
  colnames(distances) <- names(groups)
  rownames(distances) <- names(groups)

  for (i in seq_along(groups)){
    for (j in seq_along(groups)){
      if (i < j){
        distances[i, j] <- mahalanobis_distance(groups[[i]], groups[[j]], covariances[[i]], covariances[[j]], centers[[i]], centers[[j]])
      } 
      else if (i == j){
        distances[i, i] <- 0
      }
      else {
        distances[i, j] <- distances[j, i]
      }
    }
  }
  
  distances
}


distances_body <- mahalanobis_distances(data_predictors, data_log$Body_type)
print(distances_body) 
```

Расстояние Махаланобиса показывает, что машины типа Wagon близки к типу Other. Это действительно так, потому что машины типа Other -- это седаны, хэтчбэки и купе, а эти машины, как и универсалы, это обычные машины для ежедневного использования для проезда по городу, не специализированные машины. Объединим эти группы: 

```{r}
data_log <- data_log %>%
  mutate(Body_type_combined = factor(case_when(
    Body_type %in% c("Wagon", "Other") ~ "Ordinary",
    TRUE ~ as.character(Body_type)
  )))

distances_new_body <- mahalanobis_distances(data_predictors, data_log$Body_type_combined)
print(distances_new_body) 
```

**Расстояние Махаланобиса между группами по типу привода**

```{r}
distances_wheel <- mahalanobis_distances(data_predictors, data_log$Wheel_type)
print(distances_wheel) 
```

По типу привода все группы достаточно близки, поэтому ожидается, что классификация будет не очень точной.

### Классификация по типу привода

**Manova**

```{r}
manova_wheel_type <- manova(cbind(Weight, Width, Engine, CityMPG, HW_MPG, Retail, Horsepower) ~ Wheel_type, data = data_log)

summary(manova_wheel_type, 'Wilks')
summary(manova_wheel_type, 'Roy')
```

Таким образом, различия между группами значимы. 


```{r}
res_candisc <- candisc(manova_wheel_type)

structure_df <- as.data.frame(res_candisc$structure)
structure_df$label <- rownames(structure_df)
structure_df$Can1 <- structure_df$Can1 * 7
structure_df$Can2 <- structure_df$Can2 * 7


ggplot(res_candisc$scores) + 
  geom_point(aes(x = Can1, y = Can2, color = Wheel_type), size = 1.5) + 
  stat_ellipse(aes(x = Can1, y = Can2, color = Wheel_type), type = "t") + 
  geom_segment(data = structure_df, mapping = aes(x = 0, y = 0, xend = Can1, yend = Can2), 
               arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches")), size = 0.5) + 
  geom_text(data = structure_df, mapping = aes(x = Can1, y = Can2, label = label), 
            hjust = 0, nudge_x = 0.2, nudge_y = 0.1, size = 3) + 
  labs(x = "Can1", y = "Can2", color = "Тип привода") +
  theme_bw() + theme(legend.position="bottom") +
  scale_x_continuous(limits = c(-7, 7), expand = c(0, 0))
```

```{r}
summary(res_candisc)
```


#### LDA

```{r}
lda_model_cv <- lda(Wheel_type ~  Weight  + Engine + CityMPG + HW_MPG + Retail + Horsepower, data = data_log, CV = T)

lda_model <- lda(Wheel_type ~  Weight  + Engine + CityMPG + HW_MPG + Retail + Horsepower, data = data_log)
lda_model
```
**Матрица ошибок** 

***С кросс-валидацией***

```{r}
confusion_matrix <- table(Predicted = lda_model_cv$class, Actual = data_log$Wheel_type)
print(confusion_matrix)
```
***По всем данным***

```{r}
confusion_matrix <- table(Predicted = predict(lda_model)$class, Actual = data_log$Wheel_type)
print(confusion_matrix)
```

**Accuracy**

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 2)))
```


**Precision, Recall и F1-score для каждого класса**

```{r}
metrics <- calculate_metrics(confusion_matrix, data_log$Wheel_type)
datatable(metrics)
```


На основе $F_1$-score можно сказать, что классификация действительно в данном случае является не очень хорошей. Наиболее точно классифицируется группа Front_wheel (что ожидаемо, так как она самая большая и у нее самый большой вес). 

#### QDA

```{r}
qda_model <- qda(Wheel_type ~  Weight  + Engine + CityMPG + HW_MPG + Retail + Horsepower, data = data_log)

qda_model_cv <- qda(Wheel_type ~  Weight  + Engine + CityMPG + HW_MPG + Retail + Horsepower, data = data_log, CV = T)

qda_model
```

**Матрица ошибок**

***С кросс-валидацией***

```{r}
confusion_matrix <- table(Predicted = qda_model_cv$class, Actual = data_log$Wheel_type)
print(confusion_matrix)
```

***По всем данным***

```{r}
confusion_matrix <- table(Predicted = predict(qda_model)$class, Actual = data_log$Wheel_type)
print(confusion_matrix)
```

**Accuracy**

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 2)))
```


**Precision, Recall и F1-score для каждого класса**

```{r}
metrics <- calculate_metrics(confusion_matrix, data_log$Wheel_type)
datatable(metrics)
```


По сравнению с LDA качество классификации по $F_1$-score упало для All_wheel и Front_wheel (но в данном случае незначительно), а для Rear_wheel -- возросло.


### Классификация по типу кузова 

**Manova**

```{r}
manova_body_type <- manova(cbind(Length, WheelBase, Width, Weight, Engine, CityMPG, HW_MPG, Retail, Horsepower) ~ Body_type_combined, data = data_log)

summary(manova_body_type, 'Wilks')
summary(manova_body_type, 'Roy')
```

Таким образом, различия между группами значимы. 

```{r}
res_candisc <- candisc(manova_body_type)

structure_df <- as.data.frame(res_candisc$structure)
structure_df$label <- rownames(structure_df)
structure_df$Can1 <- structure_df$Can1 * 7
structure_df$Can2 <- structure_df$Can2 * 7


ggplot(res_candisc$scores) + 
  geom_point(aes(x = Can1, y = Can2, color = Body_type_combined), size = 1.5) + 
  stat_ellipse(aes(x = Can1, y = Can2, color = Body_type_combined), type = "t") + 
  geom_segment(data = structure_df, mapping = aes(x = 0, y = 0, xend = Can1, yend = Can2), 
               arrow = arrow(angle = 15, type = "closed", length = unit(0.2, "inches")), size = 0.5) + 
  geom_text(data = structure_df, mapping = aes(x = Can1, y = Can2, label = label), 
            hjust = 0, nudge_x = 0.2, nudge_y = 0.1, size = 3) + 
  labs(x = "Can1", y = "Can2", color = "Тип кузова") +
  theme_bw() + theme(legend.position="bottom") +
  scale_x_continuous(limits = c(-10, 10), expand = c(0, 0))
```
```{r}
summary(res_candisc)
```

#### LDA

```{r}
lda_model <- lda(Body_type_combined ~  Length + WheelBase + Width + Weight  + Engine + CityMPG + HW_MPG + Retail + Horsepower, data = data_log)

lda_model_cv <- lda(Body_type_combined ~  Length + WheelBase + Width + Weight  + Engine + CityMPG + HW_MPG + Retail + Horsepower, data = data_log, CV = T)

lda_model
```

**Матрица ошибок** 

***С кросс-валидацией***

```{r}
confusion_matrix <- table(Predicted = lda_model_cv$class, Actual = data_log$Body_type_combined)
print(confusion_matrix)
```
***По всем данным***

```{r}
confusion_matrix <- table(Predicted = predict(lda_model)$class, Actual = data_log$Body_type_combined)
print(confusion_matrix)
```

**Accuracy**

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 2)))
```

**Precision, Recall и F1-score для каждого класса**

```{r}
metrics <- calculate_metrics(confusion_matrix, data_log$Body_type_combined)
datatable(metrics)
```

Классификация LDA по типу кузова, основываясь на $F_1$-score, является достаточно хорошей. Наиболее точно, как и ожидается, классифицируется группа Ordinary наибольшего размера (с большим весом).

Классификацию QDA в данном случае не удается построить, так как из-за заполнения медианным знаяением признака WheelBase у Pickup ковариационная матрица становится вырожденной. 


### Классификация по типу кузова (Спортивные машины и внедорожники)


```{r}
data_log_ss <- data_log %>%
  filter(Sport == 1 | SportUtil == 1)%>%
  mutate(
  Body_type = factor(case_when(
    Sport == 1 ~ 1,
    SportUtil == 1 ~ 2,
    TRUE ~ NA_integer_
  ), levels = c(1, 2), labels = c("Sport", "SportUtil"))
)
```

#### Проверка данных на нормальность

```{r}
library(MVN)

data_da <- data_log_ss %>% 
  dplyr::select(HW_MPG, CityMPG, Retail, WheelBase,  Width, Length, Horsepower, Body_type) 

result <- mvn(data = data_da, subset = "Body_type", mvnTest = "mardia")
result$multivariateNormality
```


Основываясь на результате теста, можно считать, что данные имеют многомерное нормальное распределение.

#### Проверка гипотезы о равенстве ковариационных матриц (Box’s M Test)

```{r}
library(biotools)

res <- boxM(data_da[, 1:7], data_da$Body_type)
res
```

Гипотеза о равенстве ковариационных матриц отвергается. 


#### Проверка гипотезы о равенстве мат.ожиданий в классах

**Manova**

```{r}
manova_body_type_ss <- manova(cbind(HW_MPG, CityMPG, Retail, WheelBase,  Width, Length, Horsepower) ~ Body_type, data = data_da)

summary(manova_body_type_ss, 'Wilks')
summary(manova_body_type_ss, 'Roy')
```


```{r}
res_candisc <- candisc(manova_body_type_ss)
summary(res_candisc)
plot(res_candisc)
```

И тесты, и визуальное представление указывают на то, что мат.ожидания в классах не равны. 

**Hotelling**

```{r}
library(Hotelling)

sport <- data_da %>%
  filter(Body_type == "Sport")  %>%
  select_if(is.numeric) 

sportutil <- data_da %>%
  filter(Body_type == "SportUtil")  %>%
  select_if(is.numeric) 

hotelling_result <- hotelling.test(sport, sportutil)
hotelling_result
```

Гипотеза о равенстве мат.ожиданий отвергается. 

#### LDA

```{r}
lda_model <- lda(Body_type ~  HW_MPG + CityMPG + Retail + WheelBase + Width + Length + Horsepower, 
                 data = data_da)

lda_model_cv <- lda(Body_type ~  HW_MPG + CityMPG + Retail + WheelBase + Width + Length + Horsepower, 
                 data = data_da, CV = T)
lda_model
```

**Матрица ошибок**

***С кросс-валидацией***

```{r}
confusion_matrix <- table(Predicted = lda_model_cv$class, Actual = data_da$Body_type)
print(confusion_matrix)
```

***По всем данным***

```{r}
confusion_matrix <- table(Predicted = predict(lda_model)$class, Actual = data_da$Body_type)
print(confusion_matrix)
```

**Accuracy**

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 2)))
```

**Precision, Recall и F1-score для каждого класса**

```{r}
metrics <- calculate_metrics(confusion_matrix, data_da$Body_type)
datatable(metrics)
```


По всем метрикам получается, что качества классификации очень хорошее.

#### Визуализация

```{r}
full_predict <- predict(lda_model, data_da[,1:7]) 
ldahist(full_predict$x[,1], g = full_predict$class)
```

```{r}
lda_plot_df <- data.frame(LD1 = full_predict$x[, 1], 
                          Body_type = data_da$Body_type)

ggplot(lda_plot_df, aes(x = LD1, fill = Body_type)) +
  geom_density(alpha = 0.5) +  
  labs(title = "Распределение LD1 по классам Body_type",
       x = "LD1 (Первая дискриминантная ось)",
       fill = "Тип кузова") +
  theme_minimal() +
  theme(
    plot.title = element_text(size = 16),
    axis.title = element_text(size = 14),
    legend.title = element_text(size = 12),
    legend.text = element_text(size = 10)
  )
```

**ROC-кривая**

*По всем данным*

```{r}
ldap <- predict(lda_model, data_da[, 1:7])
pred <- prediction(ldap$posterior[,2], data_da$Body_type)
perf <- performance(pred, "tpr", "fpr") 
plot(perf, colorize = TRUE) 
AUC.ROCR <- performance(pred, "auc") 
abline(a = 0, b = 1)
text(x = .25, y = .65, paste("AUC = ", round(AUC.ROCR@y.values[[1]],5)))
```

*С кросс-валидацией*

```{r}
predcv <- prediction(lda_model_cv$posterior[,2], data_da$Body_type)
perfcv <- performance(predcv, "tpr", "fpr")
plot(perfcv, colorize = TRUE)
AUCcv <- performance(predcv, "auc")
abline(a = 0, b = 1)
text(x = .25, y = .65, paste("AUC = ", round(AUCcv@y.values[[1]],5)))
```


Рисуем ROC-кривые на одной картинке. Сверху находится ROC-кривая классификации на полных данных, что проверяется по AUC

```{r}
plot(perfcv, colorize = TRUE)
par(new = T)
plot(perf, colorize = TRUE)
text(x = .25, y = .55, paste("AUC_cv = ", round(AUCcv@y.values[[1]],5)))
text(x = .25, y = .65, paste("AUC_full = ", round(AUC.ROCR@y.values[[1]],4)))
```

#### QDA

```{r}
qda_model <- qda(Body_type ~  HW_MPG + CityMPG + Retail + WheelBase + Width + Length + Horsepower, 
                 data = data_da)

qda_model_cv <- qda(Body_type ~  HW_MPG + CityMPG + Retail + WheelBase + Width + Length + Horsepower, 
                 data = data_da, CV = T)
qda_model
```

**Матрица ошибок**

***С кросс-валидацией***

```{r}
confusion_matrix <- table(Predicted = qda_model_cv$class, Actual = data_da$Body_type)
print(confusion_matrix)
```
***По всем данным***

```{r}
confusion_matrix <- table(Predicted = predict(qda_model)$class, Actual = data_da$Body_type)
print(confusion_matrix)
```


**Accuracy**

```{r}
accuracy <- sum(diag(confusion_matrix)) / sum(confusion_matrix)
print(paste("Accuracy:", round(accuracy, 2)))
```

**Precision, Recall и F1-score для каждого класса**

```{r}
metrics <- calculate_metrics(confusion_matrix, data_da$Body_type)
datatable(metrics)
```

QDA немного уступает LDA по качеству классификации. 


**ROC-кривая**

*По всем данным*

```{r}
qdap <- predict(qda_model, data_da[, 1:7])
pred <- prediction(qdap$posterior[,2], data_da$Body_type)
perf <- performance(pred, "tpr", "fpr") 
plot(perf, colorize = TRUE) 
AUC.ROCR <- performance(pred, "auc") 
abline(a = 0, b = 1)
text(x = .25, y = .65, paste("AUC = ", round(AUC.ROCR@y.values[[1]],5)))
```

*С кросс-валидацией*

```{r}
predcv <- prediction(qda_model_cv$posterior[,2], data_da$Body_type)
perfcv <- performance(predcv, "tpr", "fpr")
plot(perfcv, colorize = TRUE)
AUCcv <- performance(predcv, "auc")
abline(a = 0, b = 1)
text(x = .25, y = .65, paste("AUC = ", round(AUCcv@y.values[[1]],5)))
```


Рисуем ROC-кривые на одной картинке. Сверху находится ROC-кривая классификации на полных данных, что проверяется по AUC

```{r}
plot(perfcv, colorize = TRUE)
par(new = T)
plot(perf, colorize = TRUE)
text(x = .25, y = .55, paste("AUC_cv = ", round(AUCcv@y.values[[1]],5)))
text(x = .25, y = .65, paste("AUC_full = ", round(AUC.ROCR@y.values[[1]],4)))
```

